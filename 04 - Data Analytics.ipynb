{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:right;\" src=\"images/smi-logo.png\"/>\n",
    "    <div style=\"float:left;color:#58288C;\"><h1>Datenanalyse und Datenmanagement</h1></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook IV: Data Analytics\n",
    "In diesem Notebook geht es um die analytische Erschließung eines weiteren Datensatzes.\n",
    "Die Merkmale werden aufbereitet, sodass im Anschluss Machine Learning Modelle entwickelt werden können.\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "[1. Einstieg: Research Approach](#kapitel1)  \n",
    "[2. Datenaufbereitung](#kapitel2)  \n",
    "[3. Modellbildung](#kapitel3)  \n",
    "[4. Modellevaluation](#kapitel4)  \n",
    "[5. Ausblick: Unsupervised K-Means Clustering](#kapitel5)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einstieg: Research Approach <a id=\"kapitel1\"/>\n",
    "\n",
    "- **Business Problem**: Nach Eingang eines Kreditantrags muss über die Vergabe und den angebotenen Zinssatz entschieden werden.  \n",
    "Diese Entscheidung hängt vom angenommenen Ausfallrisiko des Kredits ab.\n",
    "- **Research Problem**: Das Modell soll jeden Antrag Klassifizieren: Risiko vs. kein-Risiko.  \n",
    "Die Entscheidung über Vergabe und Zinssatz wird basierend auf dieser Information vom jew. Sachbearbeiter nach separat verfassten Richtlinien getroffen.\n",
    "- **Trainingsdaten**: Vergangene Kreditanträge und Ausfall j/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenaufbereitung <a id=\"kapitel2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Daten einlesen\n",
    "Auf bekannte Weise werden zunächst Pakete importiert und die Daten aus der Datenbank abgefragt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.cluster\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zum Datenbankserver herstellen\n",
    "%sql sqlite:///data/smi-data.db\n",
    "\n",
    "# SQL-Abfrage durchführen und Ergebnis in Variable result speichern        \n",
    "result = %sql SELECT * FROM credit_ger\n",
    "\n",
    "# Aus Result ein DataFrame machen\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun setzen wir den Primärschlüssel als Index des DataFrames und benennen die Merkmale griffiger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"id\"])\n",
    "df = df.rename({\n",
    "    \"Age\": \"age\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \"Job\": \"job\",\n",
    "    \"Housing\": \"housing\",\n",
    "    \"Saving accounts\": \"savings\", \n",
    "    \"Checking account\": \"cash\",\n",
    "    \"Credit amount\": \"amount\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Purpose\": \"purpose\",\n",
    "    \"Risk\": \"risk\"\n",
    "}, axis=\"columns\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worum geht es?\n",
    ">Feature Engineering ist der Prozess, Merkmale für die Algorithmen möglichst gut zugänglich zu machen. Dabei fließt in der Regel Domänenwissen des Modellierers in den Datensatz ein.\n",
    "\n",
    "In unserem Beispiel finden sich mehere String-Merkmale (Skalenniveau \"nominal\"). Da mit Texten direkt nicht gerechnet werden kann, müssen wir diese zweckmäßig in Zahlen umkodieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst betrachten wir die fraglichen Merkmale genauer\n",
    "\n",
    "binaere_merkmale = [\"sex\", \"risk\"]\n",
    "nominale_merkmale = [\"housing\", \"purpose\"]\n",
    "kardinale_merkmale = [\"savings\", \"cash\"]\n",
    "metrische_merkmale = [\"age\", \"amount\", \"duration\"]\n",
    "\n",
    "for merkmal in (binaere_merkmale + kardinale_merkmale + nominale_merkmale):\n",
    "    print(df[merkmal].value_counts())\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst erzeugen wir DataFrames für die aufbereiteten Trainingsdaten (X) \n",
    "# und Labels (y)\n",
    "\n",
    "X = pd.DataFrame()   # \"groß\" X, da Struktur eine Matrix ist\n",
    "y = pd.DataFrame()   # \"klein\" y, da Struktur ein Vektor ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf die binären Merkmale wenden wir die Dummykodierung an:\n",
    "\n",
    "y[\"risk\"] = (df.risk == \"bad\")*1   # *1 macht aus True/False 0/1\n",
    "X[\"male\"] = (df.sex == \"male\")*1   # *1 macht aus True/False 0/1\n",
    "\n",
    "print(df.sex.value_counts())\n",
    "print(X.value_counts())\n",
    "\n",
    "print(\"\")\n",
    "print(df.risk.value_counts())\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf nominale und kardinale Merkmale mit mehreren Ausprägungen wenden wir One-Hot-Encoding an\n",
    "\n",
    "beispiel = df[\"housing\"]\n",
    "one_hot_encoded = pd.get_dummies(beispiel, prefix=\"housing\")\n",
    "pd.concat([beispiel, one_hot_encoded], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung auf verbleibende Merkmale und Überführung in DataFrame X\n",
    "\n",
    "# Strings in der Purpose-Spalte kürzen, damit die Merkmalsbezeichnungen nicht zu lang werden\n",
    "\n",
    "df.purpose = df.purpose.str.slice(0,8)\n",
    "\n",
    "kodierte_merkmale = pd.get_dummies(df[nominale_merkmale + kardinale_merkmale], prefix=[\"house\",\"purpose\",\"savings\",\"cash\"])\n",
    "X = pd.concat([X, kodierte_merkmale], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die metrischen Merkmale haben deutlich verschiedene Spannweiten\n",
    "\n",
    "sns.histplot(df.loc[:,metrische_merkmale], bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch [Z-Standardisierung](https://de.wikipedia.org/wiki/Standardisierung_(Statistik)) (Normierung auf Mittelwert 0 und Standardabweichung 1) bleiben die Informationen erhalten und anfällige Algorithmen gewichten Merkmale mit großen Zahlausprägungen nicht implizit höher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merkmal in metrische_merkmale:\n",
    "    X[merkmal] = (df[merkmal]-df[merkmal].mean()) / df[merkmal].std()\n",
    "\n",
    "sns.histplot(X.loc[:,metrische_merkmale], bins=20, kde=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.loc[:,metrische_merkmale],\n",
    "          X.loc[:,metrische_merkmale]], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modellbildung <a id=\"kapitel3\"/>\n",
    "Im ersten Schritt teilen wir unsere Trainingsdaten in Trainings- und Testdaten.  \n",
    "Die Testdaten enthalten wir dem Modell zunächst vor und verwenden sie nach der Modellierung zur Gütebewertung des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)   # 20% Testdaten\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Supervised Learning: Decision Tree\n",
    "Ziel soll nun sein, das Kreditrisiko aus den anderen Merkmalen mittels eines Entscheidungsbaums vorherzusagen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=20)\n",
    "tree = tree.fit(X_train, y_train)    # zur Erinnerung: X enthält unsere aufbereiteten Fallmerkmale, Y die \"Labels\", also risk 0 oder 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisieren wir nun den Baum um die Art der Regeln zu begutachten. Jeder Knoten enthält dabei folgende Werte:\n",
    "- Split-Kriterium\n",
    "- Gini-Koeffizient\n",
    "- Anteil der Fälle in diesem Knoten\n",
    "- Anteil der Fälle mit risk 0 und risk 1\n",
    "- Entscheidung für welche Klasse (y0, y1)\n",
    "\n",
    "Der linke Pfeil bedeutet \"True\", der rechte Pfeil \"False\" bezogen auf das Knotenkriterium.\n",
    "\n",
    "Der Gini-Koeffizient ist dabei so zu lesen:\n",
    ">The degree of Gini index varies between 0 and 1, where 0 denotes that all elements belong to a certain class  \n",
    ">or if there exists only one class, and 1 denotes that the elements are randomly distributed across various classes.  \n",
    ">A Gini Index of 0.5 denotes equally distributed elements into some classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(45,20))\n",
    "t = sklearn.tree.plot_tree(tree, ax=ax, class_names=True, label=\"root\", precision=2, feature_names=X.columns, fontsize=12, proportion=True, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Supervised Learning: Logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich führen wir parallel eine Logistische Regression durch (lineare Regression für Klassifikation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = sklearn.linear_model.LogisticRegression()\n",
    "reg = reg.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Regression schätzt für jedes Datensatzmerkmal einen Gewichtungsfaktor zur Berechnung der Klasse.\n",
    "# Zur Visualisierung der Feature-Bedeutung übernehmen wir die Merkmalsbezeichnungen aus den Trainingsdaten X\n",
    "\n",
    "stat = pd.DataFrame([X.columns, reg.coef_.ravel()]).transpose()\n",
    "stat = stat.sort_values(by=[1])\n",
    "stat = stat[abs(stat[1])>0.3]   # only important parameters\n",
    "ax = sns.barplot(y=0, x=1, data=stat, orient=\"h\")\n",
    "ax.set(xlabel='Weight', ylabel='Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modellevaluation <a id=\"kapitel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Average Precision\n",
    "Im ersten Zugriff können wir uns von den Modellen die durchschnittliche Treffergenauigkeit angeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DecisionTree: {} bei Trainingsdaten, {} bei Testdaten\".format(\n",
    "    tree.score(X_train, y_train), \n",
    "    tree.score(X_test, y_test)))\n",
    "\n",
    "print(\"Regression: {} bei Trainingsdaten, {} bei Testdaten\".format(\n",
    "    reg.score(X_train, y_train), \n",
    "    reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Confusion Matrix\n",
    "Um die Güte bei Klassifikationsproblemen genauer zu untersuchen, können wir die Testdaten betrachten.  \n",
    "Die Confusion Matrix zeigt, wie oft die Modelle je Klasse (risk 0 oder 1) richtig und falsch lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15,6))\n",
    "plt.suptitle(\"Confusion Matrices\", fontsize=20)\n",
    "ax[0].set_title(\"Decision Tree\")\n",
    "ax[1].set_title(\"Logistic Regression\")\n",
    "sklearn.metrics.plot_confusion_matrix(tree, X_test, y_test, ax=ax[0])\n",
    "ax[0].set_xlabel(\"Risk predicted\")\n",
    "ax[0].set_ylabel(\"Risk actual\")\n",
    "sklearn.metrics.plot_confusion_matrix(reg, X_test, y_test, ax=ax[1])\n",
    "ax[1].set_xlabel(\"Risk predicted\")\n",
    "ax[1].set_ylabel(\"Risk actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Precision und Recall\n",
    "Bei näherer Betrachtung interessieren uns aus der Confusion Matrix zwei Facetten der Fehler, die wir als zwei Fragen formulieren können:\n",
    "- Wieviel % haben wir richtigerweise beschuldigt?\n",
    "- Wieviel % der Risikokredite haben wir entdeckt?\n",
    "\n",
    "Diese Fragen werden durch die Metriken Precision und Recall beantwortet ([mehr dazu hier](https://en.wikipedia.org/wiki/Precision_and_recall)):\n",
    "- **Precision**: Anteil der tatsächliche Kreditrisiken unter den vorhergesagten Kreditrisiken  \n",
    "- **Recall**: Anteil der erkannten Risiken unter allen Risikokrediten  \n",
    "\n",
    "Aus betriebswirtschaftlicher Sicht sind die Fehlerarten von verschiedenem Gewicht:\n",
    "- Precision: fälschlicherweise angenommenes Risiko (Feld Actual = 0, Predicted = 1) => entgangenes Geschäft\n",
    "- Recall: nicht erkanntes Risiko bedeutet Kreditausfall (Feld Actual = 1, Predicted = 0) => hohe finanzielle Einbußen\n",
    "\n",
    "Der schwerste Schaden entsteht vermutlich bei nicht erkannten Risiken und damit verbundenem Kreditausfall. Daher wäre das Gütekriterium Recall höher zu gewichten als Precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_precision = sklearn.metrics.precision_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "tree_recall    = sklearn.metrics.recall_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "\n",
    "reg_precision = sklearn.metrics.precision_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "reg_recall    = sklearn.metrics.recall_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "\n",
    "print(\"Tree:       Precision {:.2f}%, Recall {:.2f}\".format(100 * tree_precision, 100 * tree_recall))\n",
    "print(\"Regression: Precision {:.2f}%, Recall {:.2f}\".format(100 * reg_precision, 100 * reg_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ausblick: Unsupervised K-Means Clustering <a id=\"kapitel5\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []   # Inertia ist die Distanz der zuletzt fusionierten Cluster\n",
    "\n",
    "for i in range(2,8):  # Erzeuge mehrere Clusterlösungen mit 2-8 Clustern\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=i, random_state=0).fit(X)\n",
    "    inertias.append(kmeans.inertia_)  # Hänge den Inertia-Wert an unsere Liste inertias\n",
    "\n",
    "plt.figure(figsize=(10,5))   # Inertia plotten\n",
    "plt.title('Ellenbogenkriterium')\n",
    "plt.plot(range(2,8), inertias, marker=\"o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Cluster sehen gut aus!\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=3, random_state=0)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "df[\"clusters\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(2,3,figsize=(20,12))\n",
    "fig.suptitle(\"Interpretation Cluster nach Clusterzentroiden\")\n",
    "sns.scatterplot(x=df.duration, y = df.amount, hue=clusters, ax=ax[0,0], palette=\"bright\")\n",
    "sns.scatterplot(x=df.age, y = df.amount, hue=clusters, ax=ax[0,1], palette='bright')\n",
    "sns.scatterplot(x=df.age, y = df.duration, hue=clusters, ax=ax[0,2], palette='bright')\n",
    "\n",
    "ax[1,0].set_title (\"Altersverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].age, \n",
    "    df[df.clusters == 1].age,\n",
    "    df[df.clusters == 2].age], ax=ax[1,0])\n",
    "\n",
    "ax[1,1].set_title (\"Kreditsummenverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].amount, \n",
    "    df[df.clusters == 1].amount,\n",
    "    df[df.clusters == 2].amount], ax=ax[1,1])\n",
    "\n",
    "ax[1,2].set_title (\"Kreditdauerverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].duration, \n",
    "    df[df.clusters == 1].duration,\n",
    "    df[df.clusters == 2].duration], ax=ax[1,2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation der Cluster\n",
    "- **Cluster 0**: Alte Kreditnehmer mit kurzläufigen Kleinkrediten (1-2 Jahre, 1000-3000 EUR)\n",
    "- **Cluster 1**: Junge Kreditnehmer mit kurzläufigen Kleinkrediten (1-2 Jahre, 1000-3000 EUR)\n",
    "- **Cluster 2**: Eher jüngere Kreditnehmer (Mitte 30) mit längerlaufenden Großkrediten (3-4 Jahre, >5000 EUR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
