{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:right;\" src=\"images/smi-logo.png\"/>\n",
    "    <div style=\"float:left;color:#58288C;\"><h1>Datenanalyse und Datenmanagement</h1></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook IV: Data Analytics\n",
    "In diesem Notebook soll anhand des bekannten Kreditrisiko-Beispiels mit Machine Learning Modellen eine Vorhersage über Kreditwürdigkeit eines Antrages gemacht werden.\n",
    "Hierzu werden zunächst die Merkmale entsprechend aufbereitet, damit die Machine Learning Modelle damit rechnen können.\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "[1. Einstieg: Research Approach](#kapitel1)  \n",
    "[2. Datenaufbereitung](#kapitel2)  \n",
    "[3. Modellbildung](#kapitel3)  \n",
    "[4. Modellevaluation](#kapitel4)  \n",
    "[5. Ausblick: Unsupervised K-Means Clustering](#kapitel5)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einstieg: Research Approach <a id=\"kapitel1\"/>\n",
    "\n",
    "- **Business Problem**: Nach Eingang eines Kreditantrags muss über die Vergabe und den angebotenen Zinssatz entschieden werden.  \n",
    "Diese Entscheidung hängt vom angenommenen Ausfallrisiko des Kredits ab.\n",
    "- **Research Problem**: Das Modell soll jeden Antrag klassifizieren: Risiko vs. kein-Risiko.  \n",
    "Die Entscheidung über Vergabe und Zinssatz wird basierend auf dieser Information vom jew. Sachbearbeiter nach separat verfassten Richtlinien getroffen.\n",
    "- **Trainingsdaten**: Vergangene Kreditanträge und Ausfall j/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenaufbereitung <a id=\"kapitel2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Daten einlesen\n",
    "Auf bekannte Weise werden zunächst Pakete importiert und die Daten aus der Datenbank abgefragt. Über die Bekannten hinaus verwenden wir in diesem Notebook das Paket [scikit-learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql\n",
    "\n",
    "# Visualisierung-Stil für Diagramme mit Seaview setzen\n",
    "sns.set(font_scale = 1.1,\n",
    "       palette     = \"pastel\", \n",
    "       style       = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls die SQLite-Datenbank noch nicht entpackt ist, das jetzt tun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -f data/smi-data.db ] && unzip -o -d data data/smi-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zum Datenbankserver herstellen\n",
    "%sql sqlite:///data/smi-data.db\n",
    "\n",
    "# SQL-Abfrage durchführen und Ergebnis in Variable result speichern        \n",
    "result = %sql SELECT * FROM credit_ger\n",
    "\n",
    "# Aus Result ein DataFrame machen\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun setzen wir den Primärschlüssel als Index des DataFrames und benennen die Merkmale griffiger (keiner Leerzeichen, nur Kleinschreibung, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"id\"])\n",
    "df = df.rename({\n",
    "    \"Age\": \"age\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \"Job\": \"job\",\n",
    "    \"Housing\": \"housing\",\n",
    "    \"Saving_accounts\": \"savings\", \n",
    "    \"Checking_account\": \"cash\",\n",
    "    \"Credit_amount\": \"amount\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Purpose\": \"purpose\",\n",
    "    \"Risk\": \"risk\"\n",
    "}, axis=\"columns\")\n",
    "df.purpose = df.purpose.str.slice(0,8)   # Text in der Purpose-Spalte auf max. 8 Zeichen kürzen für bessere Lesbarkeit\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature Engineering & Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worum geht es?\n",
    ">Feature Engineering ist der Prozess, Merkmale für die Algorithmen möglichst gut zugänglich zu machen. Dabei fließt in der Regel Domänenwissen des Modellierers in den Datensatz ein.\n",
    "\n",
    "In unserem Beispiel begnügen wir uns mit dem Minimum: Die gewählten Machine Learning Verfahren sollen technisch mit dem Datensatz umgehen können. \n",
    "So finden sich etwa mehrere Textmerkmale im Datensatz, mit denen nicht direkt gerechnet werden kann. Diese sind entsprechend umzukodieren.\n",
    "\n",
    "Ziel ist die Zusammenstellung eines Trainingsdatensatzes bestehend aus \n",
    "- einem Dataframe X mit den Merkmalsausprägungen und \n",
    "- einem Dataframe y mit den richtigen Klassifikationsergebnissen (Kreditwürdig ja/nein)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die One-Hot-Codierung ist eine einfache Kodierform, die ein Merkmal mit mehreren Textausprägungen in mehrere 0/1-Merkmale umwandelt:\n",
    "\n",
    "beispiel = df[\"housing\"]\n",
    "one_hot_encoded = pd.get_dummies(beispiel)\n",
    "pd.concat([beispiel, one_hot_encoded], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Anwendung One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was ist zu tun?\n",
    "\n",
    "binaere_merkmale = [\"sex\", \"risk\"]                   # Umkodieren in 0/1\n",
    "nominale_merkmale = [\"housing\", \"purpose\"]           # One-Hot-Encoding\n",
    "ordinale_merkmale = [\"savings\", \"cash\", \"job\"]       # Umkodieren in Wertebereich 0..3\n",
    "metrische_merkmale = [\"age\", \"amount\", \"duration\"]   # keine Umkodierung erforderlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst erzeugen wir DataFrames für die aufbereiteten Trainingsdaten (X) \n",
    "# und Labels (y)\n",
    "\n",
    "X = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "\n",
    "# 0/1-Kodierung der binären Merkmale\n",
    "\n",
    "y[\"risk\"] = pd.get_dummies(df.risk).bad   # das \"bad\" Dummymerkmal übernehmen wir als Zielgröße \"risk\"\n",
    "X[\"male\"] = pd.get_dummies(df.sex).male   # das \"male\" Dummymerkmal übernehmen wir als erstes Merkmal in das Merkmalsdataframe X\n",
    "\n",
    "# One-Hot-Kodierung der nominalen und ordinalen Merkmale\n",
    "\n",
    "kodierte_merkmale = pd.get_dummies(df[nominale_merkmale + ordinale_merkmale])\n",
    "X = pd.concat([X, kodierte_merkmale], axis=1)   # concat fügt zwei Datasets zusammen, hier wird X das Dataset \"kodierte_merkmale\" hinzugefügt\n",
    "\n",
    "# Metrische Merkmale anfügen\n",
    "\n",
    "X = pd.concat([X,df[metrische_merkmale]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modellbildung <a id=\"kapitel3\"/>\n",
    "Im ersten Schritt legen wir ein paar Daten beiseite, um daran unser Modell später zu testen. Man spricht hier von der Aufteilung in Trainings- und Testdaten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)   # 20% der Daten werden als Testdaten beiseite gelegt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Aufbau eines Entscheidungsbaums (Decision Tree)\n",
    "Ziel soll nun sein, das Kreditrisiko aus den anderen Merkmalen mittels eines Entscheidungsbaums vorherzusagen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=20)\n",
    "tree = tree.fit(X_train, y_train)    # zur Erinnerung: X enthält unsere aufbereiteten Fallmerkmale, X_train nur die Fälle, die wir als Trainingsdaten verwenden wollen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisieren wir nun den Baum um die Art der Regeln zu begutachten. Jeder Knoten enthält dabei folgende Werte:\n",
    "- Split-Kriterium\n",
    "- Gini-Koeffizient (ignorieren wir im Rahmen dieser Veranstaltung)\n",
    "- Anteil der Fälle in diesem Knoten\n",
    "- Anteil der Fälle mit risk 0 und risk 1\n",
    "- Entscheidung für welche Klasse (y0, y1)\n",
    "\n",
    "Der linke Pfeil bedeutet \"True\", der rechte Pfeil \"False\" bezogen auf das Knotenkriterium. Die Färbung des Knotens zeigt, wie das Zielkriterium (risk) hier ausgeprägt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(35,15))\n",
    "plt.style.use('default')  # Bug in scikit-learn: Wenn Seaborn-Style gesetzt, wird der Tree nicht korrekt dargestellt, daher erst zurücksetzen\n",
    "t = sklearn.tree.plot_tree(tree, ax=ax, label=\"root\", precision=2, rounded=True, feature_names=X.columns, class_names=[\"no-risk\",\"risk\"], fontsize=12, proportion=True, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modellevaluation <a id=\"kapitel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als vermutlich einfachste Kennzahl können wir uns die durchschnittliche Treffergenauigkeit (% der Fälle die korrekt klassifiziert wurden) angeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Precision DecisionTree bei Trainingsdaten\", tree.score(X_train, y_train))\n",
    "print(\"Average Precision DecisionTree bei Testdaten\", tree.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
