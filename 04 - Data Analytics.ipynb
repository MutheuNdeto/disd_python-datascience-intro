{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:right;\" src=\"images/smi-logo.png\"/>\n",
    "    <div style=\"float:left;color:#58288C;\"><h1>Datenanalyse und Datenmanagement</h1></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook IV: Data Analytics\n",
    "In diesem Notebook geht es um die analytische Erschließung eines weiteren Datensatzes.\n",
    "Die Merkmale werden aufbereitet, sodass im Anschluss Machine Learning Modelle entwickelt werden können.\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "[1. Einstieg: Research Approach](#kapitel1)  \n",
    "[2. Datenaufbereitung](#kapitel2)  \n",
    "[3. Modellbildung](#kapitel3)  \n",
    "[4. Modellevaluation](#kapitel4)  \n",
    "[5. Ausblick: Unsupervised K-Means Clustering](#kapitel5)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einstieg: Research Approach <a id=\"kapitel1\"/>\n",
    "\n",
    "- **Business Problem**: Nach Eingang eines Kreditantrags muss über die Vergabe und den angebotenen Zinssatz entschieden werden.  \n",
    "Diese Entscheidung hängt vom angenommenen Ausfallrisiko des Kredits ab.\n",
    "- **Research Problem**: Das Modell soll jeden Antrag klassifizieren: Risiko vs. kein-Risiko.  \n",
    "Die Entscheidung über Vergabe und Zinssatz wird basierend auf dieser Information vom jew. Sachbearbeiter nach separat verfassten Richtlinien getroffen.\n",
    "- **Trainingsdaten**: Vergangene Kreditanträge und Ausfall j/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenaufbereitung <a id=\"kapitel2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Daten einlesen\n",
    "Auf bekannte Weise werden zunächst Pakete importiert und die Daten aus der Datenbank abgefragt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisierung-Stil für Diagramme mit Seaview setzen\n",
    "sns.set(font_scale = 1.1,\n",
    "       palette     = \"pastel\", \n",
    "       style       = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zudem verwenden wir in diesem Notebook das Paket [scikit-learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://scikit-learn.org/stable/\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png\" width=250/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Paket scikit-learn mit Modellen DecisionTree, Regression, K-Means Clustering\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.cluster\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung zum Datenbankserver herstellen\n",
    "%sql sqlite:///data/smi-data.db\n",
    "\n",
    "# SQL-Abfrage durchführen und Ergebnis in Variable result speichern        \n",
    "result = %sql SELECT * FROM credit_ger\n",
    "\n",
    "# Aus Result ein DataFrame machen\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun setzen wir den Primärschlüssel als Index des DataFrames und benennen die Merkmale griffiger (keiner Leerzeichen, nur Kleinschreibung, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"id\"])\n",
    "df = df.rename({\n",
    "    \"Age\": \"age\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \"Job\": \"job\",\n",
    "    \"Housing\": \"housing\",\n",
    "    \"Saving_accounts\": \"savings\", \n",
    "    \"Checking_account\": \"cash\",\n",
    "    \"Credit_amount\": \"amount\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Purpose\": \"purpose\",\n",
    "    \"Risk\": \"risk\"\n",
    "}, axis=\"columns\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausprägungen des Merkmals purpose scheinen sehr lang, daher kürzen wir diese, um in Diagrammen keine Platzprobleme mit Beschrifungen zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.purpose.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.purpose.replace({\n",
    "    \"furniture/equipment\": \"home/living\",\n",
    "    \"domestic appliances\": \"home appl.\",\n",
    "    \"vacation/others\": \"leisure\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worum geht es?\n",
    ">Feature Engineering ist der Prozess, Merkmale für die Algorithmen möglichst gut zugänglich zu machen. Dabei fließt in der Regel Domänenwissen des Modellierers in den Datensatz ein.\n",
    "\n",
    "In unserem Beispiel begnügen wir uns mit dem Minimum: Die gewählten Machine Learning Verfahren sollen technisch mit dem Datensatz umgehen können. \n",
    "So finden sich etwa mehere String-Merkmale (Skalenniveau \"nominal\") im Datensatz, mit denen nicht direkt gerechnet werden kann. Daher sind diese zweckmäßig in Zahlen umzukodieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst betrachten wir die fraglichen Merkmale genauer\n",
    "\n",
    "binaere_merkmale = [\"sex\", \"risk\"]              # nominale Merkmale mit nur zwei Ausprägunen\n",
    "nominale_merkmale = [\"housing\", \"purpose\"]\n",
    "ordinale_merkmale = [\"savings\", \"cash\"]\n",
    "metrische_merkmale = [\"age\", \"amount\", \"duration\"]\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize=(15,8))\n",
    "\n",
    "for i, merkmal in enumerate(binaere_merkmale + ordinale_merkmale + nominale_merkmale):\n",
    "    ax[i//3,i%3].set_title(merkmal, fontsize=16)\n",
    "    df[merkmal].value_counts().plot(kind=\"barh\", ax=ax[i//3,i%3])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst erzeugen wir DataFrames für die aufbereiteten Trainingsdaten (X) \n",
    "# und Labels (y)\n",
    "\n",
    "X = pd.DataFrame()   # \"groß\" X, da Struktur eine Matrix ist\n",
    "y = pd.DataFrame()   # \"klein\" y, da Struktur ein Vektor ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf die binären Merkmale wenden wir die Dummykodierung an:\n",
    "\n",
    "y[\"risk\"] = (df.risk == \"bad\")*1   # *1 macht aus True/False 0/1\n",
    "X[\"male\"] = (df.sex == \"male\")*1   # *1 macht aus True/False 0/1\n",
    "\n",
    "print(X.male.value_counts())\n",
    "print(\"\")\n",
    "print(y.risk.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf nominale und ordinale Merkmale mit mehreren Ausprägungen wenden wir One-Hot-Encoding an\n",
    "\n",
    "beispiel = df[\"housing\"]\n",
    "one_hot_encoded = pd.get_dummies(beispiel, prefix=\"housing\")\n",
    "pd.concat([beispiel, one_hot_encoded], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung auf verbleibende Merkmale und Überführung in DataFrame X\n",
    "\n",
    "# Strings in der Purpose-Spalte kürzen, damit die Merkmalsbezeichnungen nicht zu lang werden\n",
    "\n",
    "df.purpose = df.purpose.str.slice(0,8)\n",
    "\n",
    "kodierte_merkmale = pd.get_dummies(df[nominale_merkmale + ordinale_merkmale], prefix=[\"house\",\"purpose\",\"savings\",\"cash\"])\n",
    "X = pd.concat([X, kodierte_merkmale], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die metrischen Merkmale haben deutlich verschiedene Spannweiten\n",
    "\n",
    "sns.histplot(df.loc[:,metrische_merkmale], bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch [Z-Standardisierung](https://de.wikipedia.org/wiki/Standardisierung_(Statistik)) (Normierung auf Mittelwert 0 und Standardabweichung 1) bleiben die Informationen erhalten und anfällige Algorithmen gewichten Merkmale mit großen Zahlausprägungen nicht implizit höher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merkmal in metrische_merkmale:\n",
    "    X[merkmal] = (df[merkmal]-df[merkmal].mean()) / df[merkmal].std()\n",
    "\n",
    "sns.histplot(X.loc[:,metrische_merkmale], bins=20, kde=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich vorher (unnormiert) / nachher (Z-Standardisiert)\n",
    "pd.concat([df.loc[:,metrische_merkmale],\n",
    "          X.loc[:,metrische_merkmale]], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modellbildung <a id=\"kapitel3\"/>\n",
    "Im ersten Schritt teilen wir unsere Trainingsdaten in Trainings- und Testdaten.  \n",
    "Die Testdaten enthalten wir dem Modell zunächst vor und verwenden sie nach der Modellierung zur Gütebewertung des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)   # 20% Testdaten\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Supervised Learning: Decision Tree\n",
    "Ziel soll nun sein, das Kreditrisiko aus den anderen Merkmalen mittels eines Entscheidungsbaums vorherzusagen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=20)\n",
    "tree = tree.fit(X_train, y_train)    # zur Erinnerung: X enthält unsere aufbereiteten Fallmerkmale, Y die \"Labels\", also risk 0 oder 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisieren wir nun den Baum um die Art der Regeln zu begutachten. Jeder Knoten enthält dabei folgende Werte:\n",
    "- Split-Kriterium\n",
    "- Gini-Koeffizient (ignorieren wir im Rahmen dieser Veranstaltung)\n",
    "- Anteil der Fälle in diesem Knoten\n",
    "- Anteil der Fälle mit risk 0 und risk 1\n",
    "- Entscheidung für welche Klasse (y0, y1)\n",
    "\n",
    "Der linke Pfeil bedeutet \"True\", der rechte Pfeil \"False\" bezogen auf das Knotenkriterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(35,15))\n",
    "plt.style.use('default')  # Bug in scikit-learn: Wenn Seaborn-Style gesetzt, wird der Tree nicht korrekt dargestellt, daher erst zurücksetzen\n",
    "t = sklearn.tree.plot_tree(tree, ax=ax, class_names=True, label=\"root\", precision=2, feature_names=X.columns, fontsize=12, proportion=True, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Supervised Learning: Logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich führen wir parallel eine Logistische Regression durch (lineare Regression für Klassifikation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = sklearn.linear_model.LogisticRegression()\n",
    "reg = reg.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Regression schätzt für jedes Datensatzmerkmal einen Gewichtungsfaktor zur Berechnung der Klasse.\n",
    "# Zur Visualisierung der Feature-Bedeutung übernehmen wir die Merkmalsbezeichnungen aus den Trainingsdaten X\n",
    "\n",
    "stat = pd.DataFrame([X.columns, reg.coef_.ravel()]).transpose()\n",
    "stat = stat.sort_values(by=[1])\n",
    "stat = stat[abs(stat[1])>0.3]   # only important parameters\n",
    "sns.set(style = \"whitegrid\")\n",
    "ax = sns.barplot(y=0, x=1, data=stat, orient=\"h\")\n",
    "ax.set(xlabel='Weight', ylabel='Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modellevaluation <a id=\"kapitel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Average Precision\n",
    "Als vermutlich einfachste Kennzahl können wir uns zu Modellen die durchschnittliche Treffergenauigkeit (% der Fälle die korrekt klassifiziert wurden) angeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Precision DecisionTree: {} bei Trainingsdaten, {} bei Testdaten\".format(\n",
    "    tree.score(X_train, y_train), \n",
    "    tree.score(X_test, y_test)))\n",
    "\n",
    "print(\"Average Precision Regression: {} bei Trainingsdaten, {} bei Testdaten\".format(\n",
    "    reg.score(X_train, y_train), \n",
    "    reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**ACHTUNG**: Wo könnte diese Zahl im vorliegenden Fall irreführen?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Confusion Matrix\n",
    "Um die Güte bei Klassifikationsproblemen genauer zu untersuchen, können wir die Testdaten betrachten.  \n",
    "Die Confusion Matrix zeigt, wie oft die Modelle je Klasse (risk 0 oder 1) richtig und falsch lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style       = \"white\")\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "plt.suptitle(\"Confusion Matrices\", fontsize=14)\n",
    "ax[0].set_title(\"Decision Tree\")\n",
    "ax[1].set_title(\"Logistic Regression\")\n",
    "sklearn.metrics.plot_confusion_matrix(tree, X_test, y_test, ax=ax[0], cmap=\"YlGnBu\")\n",
    "ax[0].set_xlabel(\"Risk predicted\")\n",
    "ax[0].set_ylabel(\"Risk actual\")\n",
    "sklearn.metrics.plot_confusion_matrix(reg, X_test, y_test, ax=ax[1], cmap=\"YlGnBu\")\n",
    "ax[1].set_xlabel(\"Risk predicted\")\n",
    "ax[1].set_ylabel(\"Risk actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es zeigt sicht, dass ein Großteil der korrekt klassifizierten Fälle in der Klasse Risk=0 liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Precision und Recall\n",
    "Bei näherer Betrachtung interessieren uns aus der Confusion Matrix zwei Facetten der Fehler, die wir als zwei Fragen formulieren können:\n",
    "- Wieviel % haben wir richtigerweise beschuldigt?\n",
    "- Wieviel % der Risikokredite haben wir entdeckt?\n",
    "\n",
    "Diese Fragen werden durch die Metriken Precision und Recall beantwortet ([mehr dazu hier](https://en.wikipedia.org/wiki/Precision_and_recall)):\n",
    "- **Precision**: Anteil der tatsächliche Kreditrisiken unter den vorhergesagten Kreditrisiken  \n",
    "- **Recall**: Anteil der erkannten Risiken unter allen Risikokrediten  \n",
    "\n",
    "Aus betriebswirtschaftlicher Sicht sind die Fehlerarten von verschiedenem Gewicht:\n",
    "- Precision: fälschlicherweise angenommenes Risiko (Feld Actual = 0, Predicted = 1) => entgangenes Geschäft\n",
    "- Recall: nicht erkanntes Risiko bedeutet Kreditausfall (Feld Actual = 1, Predicted = 0) => hohe finanzielle Einbußen\n",
    "\n",
    "Der schwerste Schaden entsteht vermutlich bei nicht erkannten Risiken und damit verbundenem Kreditausfall. Daher wäre das Gütekriterium Recall höher zu gewichten als Precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_precision = sklearn.metrics.precision_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "tree_recall    = sklearn.metrics.recall_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "\n",
    "reg_precision = sklearn.metrics.precision_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "reg_recall    = sklearn.metrics.recall_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "\n",
    "print(\"Tree:       Precision {:.2f}%, Recall {:.2f}%\".format(100 * tree_precision, 100 * tree_recall))\n",
    "print(\"Regression: Precision {:.2f}%, Recall {:.2f}%\".format(100 * reg_precision, 100 * reg_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Untersuchung der Modellfehler\n",
    "Um Verbesserungsmöglichkeiten zu finden, können wir uns die größten Fehler des Modells ansehen.  \n",
    "Dabei ist es empfehlenswert die falsch klassifizierten Testdaten zu betrachten. Da wir im vorliegenden Beispiel jedoch zu wenig Testdaten haben, betrachten wir zu Demonstrationszwecken die Fehler in den Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tree.predict(X_train)                                   # Für Testdatensätze die Klassifikation des Trees berechnen\n",
    "Y_prob = tree.predict_proba(X_train)                             # Für Testdatensätze die Wahrscheinlichkeiten für Klassen 0 und 1 berechnen\n",
    "df_pred = pd.DataFrame(Y_pred, columns=[\"prediction\"])          # Wahrscheinlichkeiten und Zielklasse in DataFrame überführen und Spalten labeln\n",
    "df_prob = pd.DataFrame(Y_prob, columns=[\"Prob_0\", \"Prob_1\"])\n",
    "df_err = pd.concat([X_test, y_test, df_pred, df_prob], axis=1) # Diagnose-DataFrame aus Test-Merkmalen, der wahren Klasse und den Wahrscheinlichkeiten zusammenstellen\n",
    "\n",
    "df_err.dropna(inplace=True)                                    # Dataset hat immer noch 1000 Rows, Trainingsdaten wurd nur \"NaN\" ersetzt. Diese Zeilen entfernen\n",
    "\n",
    "df_err = df_err[df_err.risk != df_err.prediction]\n",
    "df_err[\"error_size\"] = df_err[[\"Prob_0\",\"Prob_1\"]].max(axis=1)\n",
    "\n",
    "df_err.sort_values(\"error_size\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, sharey=True, figsize=(12,3))\n",
    "\n",
    "sns.histplot(df_err.error_size,   stat=\"probability\", bins=8, kde=True, ax=ax[0])\n",
    "sns.histplot(df_err.loc[:,[\"amount\"]],   stat=\"probability\", bins=8, kde=True, ax=ax[1])\n",
    "sns.histplot(df_err.loc[:,[\"duration\"]], stat=\"probability\", bins=8, kde=True, ax=ax[2])\n",
    "sns.histplot(df_err.loc[:,[\"age\"]],      stat=\"probability\", bins=8, kde=True, ax=ax[3])\n",
    "\n",
    "[a.set_xlim(-4,4) for a in ax[-3:]]\n",
    "[a.grid(linestyle=\"--\", linewidth=.5) for a in ax]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FF5D02;\">Quick Task: Interpretation</span>\n",
    "Wie ist diese Darstellung zu falsch klassifizierten Kredite zu interpretieren? Wie könnte man vorgehen, um Maßnahmen zur Verbesserung des Modells zu entwickeln?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ausblick: Unsupervised K-Means Clustering <a id=\"kapitel5\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Optimale Clusteranzahl bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []   # Inertia ist die Distanz der zuletzt fusionierten Cluster\n",
    "\n",
    "for i in range(2,8):  # Erzeuge mehrere Clusterlösungen mit 2-8 Clustern\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=i, random_state=0).fit(X)\n",
    "    inertias.append(kmeans.inertia_)  # Hänge den Inertia-Wert an unsere Liste inertias\n",
    "\n",
    "plt.figure(figsize=(10,5))   # Inertia plotten\n",
    "plt.title('Ellenbogenkriterium')\n",
    "plt.plot(range(2,8), inertias, marker=\"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. K-Means Clustering durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Cluster sehen gut aus!\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=3, random_state=0)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "df[\"clusters\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(2,3,figsize=(20,12))\n",
    "fig.suptitle(\"Interpretation Cluster nach Clusterzentroiden\")\n",
    "sns.scatterplot(x=df.duration, y = df.amount, hue=clusters, ax=ax[0,0], palette=\"bright\")\n",
    "sns.scatterplot(x=df.age, y = df.amount, hue=clusters, ax=ax[0,1], palette='bright')\n",
    "sns.scatterplot(x=df.age, y = df.duration, hue=clusters, ax=ax[0,2], palette='bright')\n",
    "\n",
    "ax[1,0].set_title (\"Altersverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].age, \n",
    "    df[df.clusters == 1].age,\n",
    "    df[df.clusters == 2].age], ax=ax[1,0])\n",
    "\n",
    "ax[1,1].set_title (\"Kreditsummenverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].amount, \n",
    "    df[df.clusters == 1].amount,\n",
    "    df[df.clusters == 2].amount], ax=ax[1,1])\n",
    "\n",
    "ax[1,2].set_title (\"Kreditdauerverteilung in Clustern\")\n",
    "sns.boxplot(data=[\n",
    "    df[df.clusters == 0].duration, \n",
    "    df[df.clusters == 1].duration,\n",
    "    df[df.clusters == 2].duration], ax=ax[1,2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Interpretation der Cluster\n",
    "- **Cluster 0**: Alte Kreditnehmer mit kurzläufigen Kleinkrediten (1-2 Jahre, 1000-3000 EUR)\n",
    "- **Cluster 1**: Junge Kreditnehmer mit kurzläufigen Kleinkrediten (1-2 Jahre, 1000-3000 EUR)\n",
    "- **Cluster 2**: Eher jüngere Kreditnehmer (Mitte 30) mit längerlaufenden Großkrediten (3-4 Jahre, >5000 EUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Ausblick: 3D-Visualisierung\n",
    "Anstatt der bisherigen Diagramme können auch 3D-Visualisierungen eingesetzt werden. Optional können diese animiert oder interaktiv drehbar gestaltet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from alphashape import alphashape\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Für 3D-Scatterplot Extremwerte entfernen\n",
    "\n",
    "pltdata = df[ (df.amount   < df.amount.quantile(.95))\n",
    "            & (df.age      < df.age.quantile(.95))\n",
    "            & (df.duration < df.duration.quantile(.95))]\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(pltdata.duration, pltdata.age, pltdata.amount,\n",
    "               c=pltdata.clusters, s=100, cmap=\"viridis\")\n",
    "\n",
    "ax.set_xlabel(\"Duration\")\n",
    "ax.set_ylabel(\"Age\")\n",
    "ax.set_zlabel(\"Amount\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Scattercube langsam rotieren\n",
    "for angle in range(0, 360):\n",
    "    ax.view_init(30, angle)\n",
    "    plt.draw()\n",
    "    plt.pause(.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Durch Rotation des Scatter-Cubes klarer sichtbar:\n",
    "- Cluster Gelb: Duration hoch ODER Amount hoch\n",
    "- Cluster lila/grün: Split bei 40 Jahren und diagonal begrenzt durch Amount ODER Duration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
