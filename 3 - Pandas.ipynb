{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:right;\" src=\"images/smi-logo.png\"/>\n",
    "    <div style=\"float:left;color:#58288C;\"><h1>Introduction to Python for Data Science</h1></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook 3: Pandas\n",
    "This notebook introduces the `pandas` package as a convenient toolset to work with tabular data.\n",
    "\n",
    "## Contents\n",
    "\n",
    "[1. Importing data from APIs](#chapter1)  \n",
    "[2. Introduction to DataFrames](#chapter2)  \n",
    "[3. Simple data visualization](#chapter3)  \n",
    "[4. INSIDER Task](#chapter4)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing data from APIs <a id=\"chapter1\"/>\n",
    "\n",
    "We'll start this session by using [REST-APIs](https://en.wikipedia.org/wiki/Representational_state_transfer) to retrieve some data. In short, when using a REST API, we use the same methods as a browser does, when retrieving a webpage. But instead of an HTML description of a webpage, we retrieve the data.\n",
    "\n",
    "For practising , [this](https://github.com/public-apis/public-apis) is a list of publicly available APIs. In this notebook we are going to use `corona-api.com` that provides recent COVID infection data from the WHO and Johns Hopkins university in a compact data format.\n",
    "\n",
    "To get a first impression, point your browser to http://corona-api.com/timeline. The displayed data is a mixed data structure, some sections correspond to Python lists, others to dictionaries.\n",
    "\n",
    "Let's retrieve this data, step by step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests    # package to send http queries to the API\n",
    "\n",
    "link = \"http://corona-api.com/timeline\"   # URL to query, you can try http://corona-api.com/countries/DE instead or replace DE with another country code\n",
    "\n",
    "res = requests.get(\"https://corona-api.com/timeline\")   # send a get request to that url, store the response in variable \"res\"\n",
    "raw_data = res.json()  # this now contains the data, uncomment this line and execute the cell to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#FF5D02;\">Assignment: Analyze data structure </span>\n",
    "\n",
    "The retrieved raw data should look like this:\n",
    "\n",
    "```\n",
    "{'data': [  \n",
    "  {'updated_at': '...',\n",
    "   'date': '2022-09-13',\n",
    "   'deaths': 6467297,\n",
    "   'confirmed': 604938009,\n",
    "   'recovered': 0,\n",
    "   'new_confirmed': 508345,\n",
    "   'new_recovered': 0,\n",
    "   'new_deaths': 1446,\n",
    "   'active': 598470712},\n",
    "  {'updated_at': '...',\n",
    "   'date': '2022-09-12',\n",
    "   'deaths': 6465852,\n",
    "   'confirmed': 604429805,\n",
    "   'recovered': 0,\n",
    "   'new_confirmed': 313811,\n",
    "   'new_recovered': 0,\n",
    "   'new_deaths': 740,\n",
    "   'active': 597963953},\n",
    "   ...\n",
    "  ]\n",
    "```\n",
    "\n",
    "Please take a minute to describe for yourself what datastructures you recognize! Is it a list of dictionaries? A dictionary with keys that contain lists? A dictionary of dictionaries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to access some of the data fields with the syntax you've learned previously to access dictionaries and lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[...][...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the following two cells to see the solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data[\"data\"][0] # this returns the most recent record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data[\"data\"][0][\"confirmed\"] # this returns the number of confirmed cases from the most recent record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction to DataFrames<a id=\"chapter2\"/>\n",
    "You probably noticed that working purely with lists of dictionaries and such is not \n",
    "Pandas are the central tool for reading and manipulating data in Python. For our purposes, the `DataFrames` data structure is the most important:\n",
    "\n",
    "> **DataFrame** is a 2-dimensional labeled data structure with columns of potentially different types.  \n",
    "> You can think of it like a spreadsheet or SQL table [...]. It is generally the most commonly used pandas object.  \n",
    "> [(Source)](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html)\n",
    "\n",
    "Dataframes contain rows and columns and distinguish between regular data and indices - columns that contain an unique identifier for each row.\n",
    "I.e. our just imported covid dataset would look like this:\n",
    "\n",
    "<img src=\"images/dataframe.png\"/>  \n",
    "\n",
    "The full documentation can be found [here](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore step by step, how dataframes make life easier when exploring data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import requests\n",
    "\n",
    "raw_data = requests.get(\"https://corona-api.com/timeline\").json()  # fetch data\n",
    "df = pandas.DataFrame(raw_data[\"data\"])     # raw_data[\"data\"] contains the relevant datatable as a list of dictionaries [{},{},{},{},....], see above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at our brand new dataframe...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)   # shows the first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5) # show random n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()   # shows the number of valid entries per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with the data, we usually want to remove/rename some columns, sort the data, apply filters or partition the data.\n",
    "In this chapter we'll briefly walk the some commonly used functions to prepare datasets.\n",
    "\n",
    "> **Important**: All edits to the Dataframe create a copy with the changes, if you don't explicitly force the function to apply the changes directly (\"inplace\"). If you don't force inplace editing, the original DataFrame remains unchanged. So you usually have two options to apply changes:  \n",
    ">\n",
    "> `df = df.change_something(...)             # assign the copy with the change to the original variable`  \n",
    "> `df.change_something(..., inplace=True)    # apply the change to the original dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's prepare the dataframe...\n",
    "\n",
    "# First delete / rename some columns\n",
    "df = df.drop([\"updated_at\", \"deaths\", \"confirmed\", \"new_recovered\", \"recovered\"], axis=\"columns\")\n",
    "\n",
    "df = df.rename(columns = {                      # pass a dictionary of \"oldname\": \"newname\" pairs to rename columns\n",
    "    \"new_confirmed\": \"new_cases\", \n",
    "})\n",
    "\n",
    "df = df.sort_values(\"date\", ascending=True)     # sort data ascending\n",
    "\n",
    "df = df.set_index(\"date\")                       # set date column as unique identifier for records (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # check result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Selections and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes generally accept filters/selections in the format `[row_filter, column_filter]`. The expressions and inner workings can be quite different, we look at some of the most helpful ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select by True/False vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by passing a vector of True and False as row_filter, we toggle which rows we want to keep\n",
    "# a bool condition like the following generates such a structure, in this case with the date as index ... try it!\n",
    "\n",
    "df.new_cases > 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pass this as row_filter\n",
    "peaks = df[df.new_cases > 30000]                                # select all days with > 30.000 cases\n",
    "peaks.sort_values(\"new_cases\", ascending=False)                 # show dataframe, sorted by \"worst days\" first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.new_cases > 30000) & (df.new_deaths < 600)]              # Use bool algebra operators & (\"and\") and | (\"or\") to combine filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.new_cases > 30000) | (df.new_deaths < 600)]              # Important: don't forget the brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select by naming relevant rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select using function .loc[list of row_indexes, list of column names]:\n",
    "\n",
    "df.loc[\"2020-08-01\",\"cases\"]   # single day, single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"2020-09-01\":\"2020-09-07\", \"deaths\":\"active\"]  # ranges of days, range of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"2020-09-01\":\"2020-09-07\", : ]  # ranges of days, all columns (full range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"2020-02-01\",\"2020-03-01\"], [\"deaths\", \"active\"]]  # subsets via lists of days (index) and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#FF5D02;\">Assignment: Data selection</span>\n",
    "\n",
    "Generate a new dataframe that only contains new_cases for January 2021!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Calculations and simple statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do calculations with columns similar to single variables\n",
    "\n",
    "df[\"death_rate\"] = df.new_deaths / df.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate common descriptive statistics for numeric columns of the whole dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or for a single column\n",
    "df.new_cases.describe()   # note the scientific notation (\"e notation\") in the result, if unknown, check here: https://en.wikipedia.org/wiki/Scientific_notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just a specific metric :-)\n",
    "\n",
    "print(\"New Cases\")\n",
    "print(\"Mean: \", df.new_cases.mean())\n",
    "print(\"Median: \", df.new_cases.median())\n",
    "print(\"Maximum: \", df.new_cases.max())\n",
    "print(\"20% quantile: \", df.new_cases.quantile(0.2))\n",
    "print(\"80% quantile: \", df.new_cases.quantile(0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#FF5D02;\">Assignment: Compare descriptive statistics</span>\n",
    "\n",
    "Calculate the average of new cases of Jan 2021 and Feb 2021! Which one is bigger?\n",
    "\n",
    "Try it first, if you need hints, expand the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "> **Hints**\n",
    "> - Use the .loc[] function to select the months (see above examples for index ranges)\n",
    "> - Use the .mean() function to calculate the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Simple data visualization<a id=\"chapter3\"/>\n",
    "\n",
    "There are numerous data visualization packages available for Python (e.g. matplotlib, seaborn). The [Python Graph Gallery](https://www.python-graph-gallery.com) gives a lot of examples with code snippets.\n",
    "\n",
    "Pandas include a `.plot()` function that automatically calls the respective functionality from a visualization package (matplotlib, by default).\n",
    "\n",
    "This sections shows a lot of examples to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_quarter = df.new_cases[-90:-1]\n",
    "last_quarter.plot()  # plot the new cases for the last 90 days \n",
    "\n",
    "# (if you're unsure about the syntax, recheck the Python basics notebook or google python negative indexing for lists or dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make it look a little nicer, for a list of all parameters check https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "\n",
    "last_quarter.plot(kind=\"area\", figsize=(18,5), \n",
    "                  color=\"lightblue\", legend=True,\n",
    "                   title=\"New infections during the last quarter\",\n",
    "                   ylabel=\"Number of cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the distribution of daily case count for January 2021 with a boxplot\n",
    "last_quarter.plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a histogram to check the overall distribution\n",
    "last_quarter.plot(kind=\"hist\", edgecolor=\"white\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scatterplots (plot x vs y values as dots) we need a little different syntax and come back to the full dataframe, containing all columns:\n",
    "df[-90:-1].plot(kind=\"scatter\", x=\"new_cases\", y=\"new_deaths\", color=\"blue\", title=\"Todesfälle vs. Neuinfektionen pro Tag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show multiple data series in a single plot, just put the statements in the same notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[-90:-1].new_cases.plot  (kind=\"hist\", figsize=(16,5), alpha=0.5, color=\"blue\", legend=True, \n",
    "                            label=\"last 90 days\", title=\"Number of days with x new infections, quarterly comparison\") \n",
    "df[-180:-91].new_cases.plot(kind=\"hist\", figsize=(16,5), alpha=0.2, color=\"green\", legend=True, \n",
    "                            label=\"previous 90 days\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. INSIDER Task<a id=\"chapter4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task as group of 2-3 ppl:\n",
    "- Briefly check out https://teleport.org to understand what data this assignment is about\n",
    "- Pick 3-5 big cities that you're interested in benchmarking\n",
    "- Use the [teleport API](https://developers.teleport.org/api/) to compile a single table that lists all life quality scores for the respective urban areas. The resulting table should look like this\n",
    "   Name | City1 | City2 | City3 | ...\n",
    "   :-----------|:--:|:--:|:--:|:--:\n",
    "   Housing | 7.2 | 6.9 | ... | ...\n",
    "   Cost of Living | 5.7 | 9.1 | ... | ...\n",
    "   ... | ... | ... | ... | ...\n",
    "- Compute the total score of the urban areas by averaging all individual scores of each area\n",
    "- Round all scores to one decimal digit and add the mean scores to your result dataframe\n",
    "- Generate a horizontal bar chart to visualize your findings\n",
    "- Make sure, all key steps of your code have concise english comments\n",
    "- Submit your commented code + the mean scores of your cities as solution to the INSIDER task\n",
    "\n",
    "> *Remarks regarding scoring of this task*: Task is considered basically completed if your code produces a table of correct scores for each urban area. The task is done well if your code generates a single table with all scores, can display the demanded bar chart and compute the means successfully. The task is done perfect if you round all values, append the mean values to the table and this way include the mean scores in your bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Develop your code in multiple cells so you can check the output of every step\n",
    "- For the final solution you will need a loop to fetch data for all the cities, but don't start this way. First get the task working for a single city, then carefully introduce more complexity to your code.\n",
    "- You have seen all required operations in the notebooks you worked through for this task; feel free to use this as copy/paste reference. Where unsure use google to find more examples of a certain operation.\n",
    "- Getting the quality scores from teleport API requires going through these steps: \n",
    "  * look up the city, get the link to the city data\n",
    "  * use the city data link to get the link to the urban area of the city\n",
    "  * use the urban area data link to get the link to the scores\n",
    "  * retrieve the scores\n",
    "- You can save your work by simply copy/pasting your code to an empty document on your computer or downloading this notebook (File -> Download). After re-opening the Jupyter environment, you can re-upload the notebook by drag/dropping the downloaded notebook to the file explorer on the left hand side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Working with API results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Before writing the code, you might want to walk through the sequence of queries in a browser. Start with the city search and copy/paste the next required link. They look like this:\n",
    "   * Link to city search: `http://api.teleport.org/api/cities/?search=CityName`\n",
    "   * Link to city data: `https://api.teleport.org/api/cities/geonameid:???????/`\n",
    "   * Link to urban area: `https://api.teleport.org/api/urban_areas/slug:???????/`\n",
    "   * Link to scores: `https://api.teleport.org/api/urban_areas/slug:??????/scores/`\n",
    "- Getting the required bits of information from the retrieved raw (JSON) data is a little cumbersome. The cell below contains an example query that demonstrates how to dig layer by layer into the first API response. If this feels confusing, revisit notebook #2 and recheck the sections about lists and dictionaries, especially the person example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Preparing your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember: operations like drop, rename, etc. create and return a copy of the dataframe. Use inplace editing like `df.rename(..., inplace=True)` or assign the changed dataset to the original name like in `df = df.rename(...)` to make your changes persistent\n",
    "- To approach the problem stepwise, create and prepare separate dataframes for each city in your loop and join the dataframes at the end outside the loop. \n",
    "- In might be useful to drop the color column and rename column \"score_out_of_10\" to the city name in dataframe preparation.\n",
    "- Don't forget to set the index. \n",
    "- There are at least two options to join multiple dataframes:\n",
    "   * Use the `.loc[]` function to piece your result dataframe together, like `df.loc[:,\"columnX\"] = ...` to add a column\n",
    "   * Check the documentation of `pandas.concat()` function online and use it to generate your result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some things to get you started...\n",
    "You can start working directly in the cell below or create a new notebook with File->New->Notebook and copy the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "\n",
    "# Entry link to teleport API\n",
    "url_citysearch = \"http://api.teleport.org/api/cities/?search=\"   # append the name of the city you want to search for at the end of this string\n",
    "\n",
    "# Cities to analyze\n",
    "cities = [\"city1\", \"city2\", \"city3\", ...]\n",
    "scores = []                                  # empty list, your loop can add the results here later\n",
    "\n",
    "# Starting point / example: Lookup of exemplary city\n",
    "\n",
    "result = requests.get(url_citysearch + \"Berlin\")\n",
    "link_to_city_data = result.json()[\"_embedded\"][\"city:search-results\"][0][\"_links\"][\"city:item\"][\"href\"]\n",
    "print(link_to_city_data)\n",
    "\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
